---
title: "Linear Modeling Lab 2"
author: "Sports Camp Crew"
date: "June 17, 2019"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE)
```

# Plotting for linear modeling

## Goals

As a continuation of yesterday's lab, we will continue linear modeling, focusing on building and assessing linear models in R.  In this lab we will


+ Extract the best fit line along with confidence and prediction intervals for simple linear regression

+ Look at diagnostic plots to determine whether a linear model is a good fit for our data.

+ Assess our fitted linear models.


## Warm up:

On Sunday, the USA Women's soccer team won the FIFA World Cup with a 3-0 victory versus Chile.  We are interested in the number of minutes played for all women's soccer players.

**Question A**. If our response variable is minutes played, what do you think our covariates should include?

**Question B**.  Can you think of any common confounders?

**Question C**.  What external variables may be important to model? (e.g. time of match, location of match, etc.)




## Preliminaries

Execute the following code chunk to load the necessary packages for this lab:

```{r, echo = FALSE}
library('tidyverse')
library('GGally')
```

Execute the following code chunk to a) load the necessary data for this lab, b) compute a few variables we will use in this lab, and c) subset out players with low minute totals (fewer than 250 minutes played in a season):

```{r}
nba <- read.csv("https://raw.githubusercontent.com/ryurko/CMSACamp/master/data/intro_r/nba_2019_player_stats.csv?token=AFKSV7EZOGYYTLAWNZ7YRPC453VNQ")

nba$field_goal_percentage <- nba$field_goals / nba$field_goal_attempts
nba$three_point_percentage <- nba$three_pointers / nba$three_point_attempts
nba$free_throw_percentage <- nba$free_throws / nba$free_throw_attempts
nba_subset <- filter_all(nba, all_vars(!is.na(.))) %>% 
  filter(minutes_played > 250) 
```


## Exploratory Data Analysis Revisited

Yesterday we looked at the scatterplot of minutes played versus field goal percentage and plotted predicted points.  Today we will add the best fit line.

```{r}
ggplot(data = nba_subset, aes(x = field_goal_percentage, y = minutes_played)) + geom_point()
```

Fit the linear model to the data, using only field goal percentage as the explanatory variable.

```{r}
fgp_linmod <- lm(minutes_played ~ field_goal_percentage, data = nba_subset)
summary(fgp_linmod)
```

**Question 1.** Do you think this model explains the data well?  Why or why not?

**Question 2.** Can you interpret the coefficient of field goal percentage?

**Question 3.** What would you tell a NBA coach to take away from this model, if anything?

`ggplot` has it's own built in functions to add trend lines with defaults.  Below, `geom_smooth()` with `method = 'lm'` plots the best fit line between our `y` and `x` variables along with a 95% confidence interval for each point.

```{r}
ggplot(data = nba_subset, aes(x = field_goal_percentage, y = minutes_played)) + 
  geom_smooth(method = 'lm') +
  geom_point()
```

More generally, we believe it is important that it is more important to have full control over what is being plotted and so we recommend manipulating and extracting the relevant information straight from your model.  This way you will not be wondering what is being plotted (e.g. confidence vs. prediction intervals).

We will instead manipulate our NBA data frame to include our new data.

```{R}
y_pred <- predict(object = fgp_linmod, data = nba_subset)
head(y_pred)

y_ci <- predict(object = fgp_linmod, data = nba_subset, interval = "confidence", level = .95)
head(y_ci)

reg_df <- cbind(nba_subset, y_ci)


ggplot(data = reg_df, aes(x = field_goal_percentage)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = factor(1)), alpha = .3) + 
  geom_line(aes(y = fit, col = factor(1)), size = 2) +
  geom_point(aes(y = minutes_played)) +
  scale_color_manual(values = c("blue"), lab = "", name = "Regression line and 95% CI") +
  scale_fill_manual(values = c("blue"), lab = "", name = "Regression line and 95% CI")
```

**Question 4.** Can you explain why we mapped the color and fill?  Hint: Take away the last two lines with `scale_` and remove the `col` and `fill` aesthetic in `geom_ribbon()` and `geom_line()`.

**Question 5.** What happens when you change the interval in `predict()` to `interval = "prediction"?  Which one produces larger intervals?  Which one produces a standard width?  Is using the prediction interval useful?

The `predict()` function is applied to a variety of regression methods, not just linear regression.  To look at the arguments for linear regression, use `?predict.lm`.


## Linear model with one continuous covariate and one categorical covariate

Essentially, categorical variables make it so we are changing the intercept of our regression line (as the categorical covariate coefficient will either be 0 or a fixed value).  We can visualize this on our graph.

```{r}
fieldgoalpos_linmod <- lm(minutes_played ~ field_goal_percentage + position, data = nba_subset)
summary(fieldgoalpos_linmod)
```

**Question 6a.** What do you notice about the different lines?


```{r}
y_ci <- predict(object = fieldgoalpos_linmod, data = nba_subset, interval = "confidence", level = .95)
head(y_ci)

reg_df <- cbind(nba_subset, y_ci)


ggplot(data = reg_df, aes(x = field_goal_percentage, col = position, fill = position,
                          group = position)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .3, col = NA) + 
  geom_line(aes(y = fit), size = 2) +
  geom_point(aes(y = minutes_played)) 
```

**Question 6b.** Can you make the above plot less busy using `facet_wrap()` on the `position` covariate?

```{R}
## R code here
```

**Question 7.** Do you think adding the `position` variable is a good idea?

**Question 8.** Add appropriate titles, labels, and legend titles and labels to the graph.

**Question 9.**  We see that power forward (PF) and small forward (SF) lines nearly overlap as do the point guard (PG) and shooting guard (SG).  For those of you familiar with basketball, does this make sense?

**Question 10.** Let's combine the forward positions together and the guard positions together.

```{R}

pos_df <- nba_subset %>% mutate(pos_combined = fct_collapse(position, Guard = c("SG", "PG"), 
                                                  Forward = c("SF", "PF"),
                                                  Center = "C"))

fieldgoalpos_linmod2 <- lm(minutes_played ~ field_goal_percentage + pos_combined, data = pos_df)

summary(fieldgoalpos_linmod2)



```

```{R}
y_ci2 <- predict(object = fieldgoalpos_linmod2, data = pos_df, interval = "confidence", level = .95)
pos_df2 <- cbind(pos_df, y_ci2)




ggplot(data = pos_df2, aes(x = field_goal_percentage, col = pos_combined, fill = pos_combined,
                          group = pos_combined)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .3, col = NA) + 
  geom_line(aes(y = fit), size = 2) +
  geom_point(aes(y = minutes_played)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2")
  
```

**Question 11.** Which model do you think is better?  The one where we combined the positions or the one where we left them alone?  Justify your answer.


## Visualizing linear regression with multiple covariates

When we have more than one continuous variable we have to get creative in how we display our results.  For example if we look at minutes played vs. field goal percentage and defensive rebounds we do not see the full picture by plotting minutes played vs. field goal percentage.  One way to look at the total fit of the model is to look at the standardized residuals of the model vs. the fitted values (e.g. standardized $y - \hat{y}$ vs. $\hat{y}$).

```{r}
fg_dr_linmod <- lm(minutes_played ~ field_goal_percentage + defensive_rebounds, data = nba_subset)
summary(fg_dr_linmod)
```

**Question 9**.  From the model summary results, do you think adding defensive rebounds is important?  Do you think this model has a strange result? (Hint: look at the coefficient of field goal percentage).


Let's extract the standardized residuals.
```{r}
std_resid <- rstandard(fg_dr_linmod)
range(std_resid)
fit <- fg_dr_linmod$fitted.values # another way to extract the fitted values
plot_df <- cbind(nba_subset, std_resid, fit)

ggplot(data = plot_df, aes(x = fit, y = std_resid)) + geom_point() + geom_hline(yintercept = 0, col = "red")

```

**Question 10**.  What can you say about the residuals?  Do you think this model is a good fit?  What does a negative residual mean in the context of our model?


## More EDA

It always good to look at pairs plot of our covariates and response variable.  The library ``Ggally` has a function to do just this.

```{R}
vars <- c("minutes_played", "field_goal_percentage", "defensive_rebounds", "position")

ggpairs(nba_subset, vars, title = "Pairs plot")

```

**Question 11**.  What are the diagonals of the above plot showing?

**Question 12**.  Which pairs of variables seem positively related?  Do any seem negatively related?

**Question 13**.  Can you repeat the above instead using our combined positions?  What changes?

## More model diagnostics

The standardized residuals vs. predicted values are a model diagnostic that can be included with just about any model.  We can also look at other plots to assess our model.  Here is one from the `ggfortify` package in `R`.  [This website](https://data.library.virginia.edu/diagnostic-plots/) has some good descriptions of how to use diagnostic plots.

```{R}
library(ggfortify) ## install the package if you need to
autoplot(fg_dr_linmod , label.size = 3)

```

The first plot is residuals vs. fitted, which looks very close to the model diagnostic we plotted earlier.  

The second plot is a [Q-Q plot](http://www.stat.cmu.edu/~cshalizi/TALR/TALR.pdf) (p. 93).  Without getting too much into the math behind them, the closer the observations are to the dotted line, the better your model fit is.  It is bad for the observations to diverge from the dotted line in a systematic way.


The third plot looks at the square root of the absolute value of the standardized residiuals.  We want to check for homoskedascity of errors (equal variance).  If we did have equal variance, what would we expect to see?

The fourth plot is residuals vs. leverage which helps us identify "influential" points.

**Question 14.** Which points are influential?  Can you identify the players?  In which ways do you think these players are influential?

**Question 15.** Based on all the above diagnostics and EDA we looked at, do you think the minutes played regressed on the field goal percentage and defensive rebounds is a good model?  Why or why not?  How would you improve the model?


# Bonus Questions

Where the bonus is making lots of graphs.

1. Can you find the pair of variables with the strongest linear relationship (both positive or negative)?

2. Does it make sense to use those two variables in a regression framework?  That is, does it make sense to have one explained by the other?  (not necessarily caused by).

3. What happens when you use a linear regression to predict the minutes played from all the variables?  What about if you remove player?  What if you remove team and player?

4. Find **your** best fit model.  Justify why you chose such a model.  What would you recommend to an NBA coach from the results of your model?


